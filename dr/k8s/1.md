# k8s删除namespaces状态一直为terminating问题处理

```sh
# 新开启一个终端;此命令启动了一个代理服务来接收来自你本机的HTTP连接并转发至API服务器，同时处理身份认证
[roo@master ~]# kubectl proxy
# 编写脚本1.sh ; $1参数即为删除不了的ns名称
[roo@master ~]# vim 1.sh
#!/bin/bash

set -eo pipefail

die() { echo "$*" 1>&2 ; exit 1; }

need() {
        which "$1" &>/dev/null || die "Binary '$1' is missing but required"
}

# checking pre-reqs

need "jq"
need "curl"
need "kubectl"

PROJECT="$1"
shift

test -n "$PROJECT" || die "Missing arguments: kill-ns <namespace>"

kubectl proxy &>/dev/null &
PROXY_PID=$!
killproxy () {
        kill $PROXY_PID
}
trap killproxy EXIT

sleep 1 # give the proxy a second

kubectl get namespace "$PROJECT" -o json | jq 'del(.spec.finalizers[] | select("kubernetes"))' | curl -s -k -H "Content-Type: application/json" -X PUT -o /dev/null --data-binary @- http://localhost:8001/api/v1/namespaces/$PROJECT/finalize && echo "Killed namespace: $PROJECT"

[root@master ~]# bash 1.sh kubevirt
```

# init初始化测试失败

```shell
# 进行初始化测试时出错
[root@master ~]# kubeadm init --config=./init.yaml --dry-run 2>error.log
[root@master ~]#cat error.log
```

>error execution phase preflight: [preflight] Some fatal errors occurred:
>[ERROR CRI]: container runtime is not running: output: time="2024-03-08T09:53:29+08:00" level=fatal msg="unable to determine runtime API version: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial unix /run/containerd/containerd.sock: connect: no such file or directory\""
>, error: exit status 1
>[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
>To see the stack trace of this error execute with --v=5 or higher

**报错原因**

> Failed to start containerd container runtime.
>
> containerd未启动或启动失败

**解决办法**

```shell
# 检查containerd状态信息
[root@master ~]# systemctl status containerd
# 启动失败或处于load信息，使用jour进行排错
[root@master ~]#systemctl start containerd
[root@master ~]#journalctl -xe

# 启动失败重要解决方法，检查config.toml文件配置是否有问题(重点检查语法，括号这些是否对其)
[root@master ~]#vim /etc/containerd/config.toml
# 修改后再重启；erro.log中没有内容则表示没问题；执行安装
[root@master ~]#mkdir -p $HOME/.kube
[root@master ~]#sudo cp -i /etc/kubernetes/tmp/kubeadm-init-dryrun3240937431/admin.conf $HOME/.kube/config
[root@master ~]#sudo chown $(id -u):$(id -g) $HOME/.kube/config
[root@master ~]# kubeadm init --config=./init.yaml
```

# init初始化失败

```shell
# 开始初始化系统时失败
[root@master ~]# kubeadm init --config=./init.yaml
```

> [init] Using Kubernetes version: v1.26.0
> [preflight] Running pre-flight checks
> error execution phase preflight: [preflight] Some fatal errors occurred:
>         [ERROR Port-10259]: Port 10259 is in use
>         [ERROR Port-10257]: Port 10257 is in use
>         [ERROR FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml]: /etc/kubernetes/manifests/kube-apiserver.yaml already exists
>         [ERROR FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml]: /etc/kubernetes/manifests/kube-controller-manager.yaml already exists
>         [ERROR FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml]: /etc/kubernetes/manifests/kube-scheduler.yaml already exists
>         [ERROR FileAvailable--etc-kubernetes-manifests-etcd.yaml]: /etc/kubernetes/manifests/etcd.yaml already exists
>         [ERROR Port-10250]: Port 10250 is in use
> [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
> To see the stack trace of this error execute with --v=5 or higher

**报错原因**

> 1. 当前环境已经执行过一次init初始化，导致环境不干净
> 2. init.yaml文件内容有错误
> 3. 端口已经被占用
>
> ```shell
> # 获取报错信息途径
> [root@master ~]#kubeadm init --config=init.yaml --dry-run 2>error.log
> [root@master ~]# cat error.log 
> ```

**解决办法**

```shell
# 1、初始环境，还原干净环境；谨慎操作，若有重要内容，备份下方rm -rf的内容
[root@master ~]# kubeadm reset
[root@master ~]# rm -rf /etc/kubernetes/manifests/
[root@master ~]# rm -rf /var/lib/etcd/
[root@master ~]# systemctl restart kubelet
# 2、修改init.yaml文件；若没错就跳过(我的报错为地址写错advertiseAddress: 192.168.1.12)
# 修改完后，重新执行安装其
[root@master ~]# rm -rf error.log /etc/kubernetes/tmp
# 开始初始化并指定error日志目录
[root@master ~]# kubeadm init --config=init.yaml |tee init/init.log
# 3、通过ss -lntp | grep 10259 获取几个端口的pid kill -9 pid
```

> [注]：	